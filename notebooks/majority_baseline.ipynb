{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "from datasets import load_dataset, ClassLabel"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "def binarize_mnli(dataset, remove_neutral=True):\n",
    "    if remove_neutral:\n",
    "        # neutral class has label 1\n",
    "        dataset = dataset.filter(lambda example: example[\"label\"] != 1)\n",
    "\n",
    "    # change labels of contradiction examples from 2 to 1\n",
    "    def change_label(example):\n",
    "        # convert labels 2 into labels 1. this merges the neutral and contradiction class\n",
    "        example[\"label\"] = 1 if example[\"label\"] == 2 else example[\"label\"]\n",
    "        return example\n",
    "        \n",
    "    # change labels\n",
    "    dataset = dataset.map(change_label)\n",
    "\n",
    "    # change features to reflect the new labels\n",
    "    features = dataset[\"train\"].features.copy()\n",
    "    features[\"label\"] = ClassLabel(num_classes=2, names=['entailment', 'contradiction'], id=None)\n",
    "    dataset = dataset.cast(features)  # overwrite old features\n",
    "        \n",
    "    return dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "def load_paws_qqp_dataset(path=\"/llmft/data/paws_qqp/dev_and_test.tsv\"):\n",
    "    data_files = {\"validation\": path}\n",
    "    dataset = load_dataset(\"csv\", data_files=data_files, sep=\"\\t\")\n",
    "    dataset = dataset[\"validation\"]\n",
    "\n",
    "    def _clean_data(sample):\n",
    "        # the paws-qqp dataset was created as a stream of bytes. So every sentence starts with \"b and ends with \".\n",
    "        # we remove these\n",
    "        sample[\"sentence1\"] = sample[\"sentence1\"][2:-1]\n",
    "        sample[\"sentence2\"] = sample[\"sentence2\"][2:-1]\n",
    "        return sample\n",
    "\n",
    "    dataset = dataset.map(_clean_data, batched=False)\n",
    "    dataset = dataset.rename_column(\"id\", \"idx\")\n",
    "\n",
    "    return dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "def load_cola_ood_dataset(path=\"/llmft/data/cola_ood/dev.tsv\", label=None, cache_dir=None):\n",
    "    data_files = {\"validation\": path}\n",
    "    dataset = load_dataset(\"csv\", data_files=data_files, sep=\"\\t\", column_names=[\n",
    "                           'code', 'label', 'annotation', 'sentence'], cache_dir=cache_dir)\n",
    "    dataset = dataset[\"validation\"]\n",
    "\n",
    "    return dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "# task_name = \"rte\"\n",
    "task_name = \"mnli\"\n",
    "# task_name = \"qqp\"\n",
    "# task_name = \"cola\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "source": [
    "dataset = load_dataset(\"glue\", task_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "if task_name == \"mnli\":\n",
    "    dataset = binarize_mnli(dataset, remove_neutral=True) # mnli\n",
    "    # dataset = binarize_mnli(dataset, remove_neutral=False) # mnli-original"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "dataset"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "print(\"task_name:\", task_name)\n",
    "# for split in [\"train\", \"validation\"]:\n",
    "for split in [\"train\", \"validation_matched\"]:\n",
    "    c = Counter(dataset[split][\"label\"])\n",
    "    total = len(list(c.elements()))\n",
    "    print(\"Total number of sampels:\", total)\n",
    "    print(split)\n",
    "    for k in c:\n",
    "        print(f\"fraction of labels per class: {k}={c[k] / total}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# dataset = load_paws_qqp_dataset()\n",
    "dataset = load_cola_ood_dataset()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "c = Counter(dataset[\"label\"])\n",
    "total = len(list(c.elements()))\n",
    "print(\"Total number of sampels:\", total)\n",
    "for k in c:\n",
    "    print(f\"fraction of labels per class: {k}={c[k] / total}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
